{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Scale Encoder-Decoder (BART) Sampling\n",
    "> Empirical netbook to sample bart for method2test benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import torch\n",
    "import importlib\n",
    "from fairseq.models.transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rationalization = importlib.import_module(\"sequential-rationales.fairseq.rationalization\")\n",
    "rationalize = rationalization.rationalize_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from matplotlib import colors\n",
    "import os\n",
    "#from rationalization import rationalize_lm, rationalize_conditional_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    corpus = 'fm_fc_ms_ff' #<-- Scope\n",
    "    #data_path = Path('../semeru-datasets/athena_test/' + corpus + '/')\n",
    "    data_path_raw = Path('../semeru-datasets/athena_test/'+ corpus + '/raw/')\n",
    "    tokenizer_path = Path('../scripts/tokenizer/')\n",
    "    return {\n",
    "        'bpe_path' : tokenizer_path / 'universal_tokenizer/roberta_aug_spaces',\n",
    "        'eval_raw': [data_path_raw / 'eval/input.methods.txt',\n",
    "                        data_path_raw / 'eval/output.tests.txt'],\n",
    "        'test_raw': [data_path_raw / 'test/input.methods.txt', \n",
    "                        data_path_raw / 'test/output.tests.txt'],\n",
    "        'train_raw': [data_path_raw / 'train/input.methods.txt', \n",
    "                        data_path_raw / 'train/output.tests.txt'],\n",
    "        'data_labels' : ['test_raw'],#['eval_raw','test_raw','train_raw'], <----- Just Test\n",
    "        #'output_pandas' : data_path / 'pandas/',\n",
    "        'out_processed' : '/workspaces/code-rationales/data/athena-test-out/out_processed/',\n",
    "        'model_name_or_path' : '/workspaces/code-rationales/data/bart-fairseq/checkpoint_dir_athena_ms/models/', #Model Path\n",
    "        'checkpoint_file': 'checkpoint_best.pt', #Model\n",
    "        #'data_preprocessed':'/home/davidna/data/dummy/sequential-rationales/fairseq/fairseq/data-bin/bins/',\n",
    "        'output_results' : '/workspaces/code-rationales/data/athena-test-out/icse_results/' \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint_best.pt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = param_default()\n",
    "params['checkpoint_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../semeru-datasets/athena_test/fm_fc_ms_ff/raw/eval/input.methods.txt'),\n",
       " PosixPath('../semeru-datasets/athena_test/fm_fc_ms_ff/raw/eval/output.tests.txt')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['eval_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting experiments \n",
    "#! export CUDA_VISIBLE_DEVICES=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(bpe_path):\n",
    "    return ByteLevelBPETokenizer(str(bpe_path)+'-vocab.json',str(bpe_path)+'-merges.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy_decode(bpe_java):\n",
    "    return bpe_java.replace(' ','').replace('Ġ',' ').replace('Ċ','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_java(minified_java):\n",
    "    \"tries to undo Michele's minification. Works decently, although for loops and sets get newlines inserted, and there are no empty lines or comments\"\n",
    "    minified_java = minified_java.replace('{','{\\n').replace('}','}\\n').replace(';',';\\n')\n",
    "    num_indents = 0\n",
    "    pretty_java = ''\n",
    "    for line in minified_java.splitlines():\n",
    "        if line.lstrip().startswith('}'):\n",
    "            num_indents -= 1\n",
    "        pretty_java += num_indents*'    '+line+'\\n'\n",
    "        if line.endswith('{'):\n",
    "            num_indents += 1\n",
    "        if line.endswith('}') and not line.lstrip().startswith('}'):\n",
    "            num_indents -= 1\n",
    "    return pretty_java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(params['bpe_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def method_size_vector( method_vector ):\n",
    "    '''Return the size of the tokens for a give method based on id\n",
    "        Assuming that method_vector is an array of tokens\n",
    "    '''\n",
    "    input_ids = [ len(mtd) for mtd in method_vector ]\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Set Code Preprocessess configured datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_set_code():\n",
    "    data = {}\n",
    "    for label in params['data_labels']:\n",
    "        for val, path_data in enumerate( params[ label ] ):\n",
    "            df = pd.read_csv( path_data, sep=\"\\n\", header=None, names=[label+str(val)]) #reading file\n",
    "            df[label+'_bpe' + str( val )] = [ enc.tokens for enc in tokenizer.encode_batch( df[label+str(val)].values ) ] #bpe\n",
    "            df['method_size' + str( val )] = method_size_vector( df[label+'_bpe'+str(val)].values ) #counting tokens\n",
    "            data[label+str(val)] =  df  \n",
    "        #data[-1].columns = [ label ]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data = super_set_code() #[WARNING] Use it when not computed! Otherwise use Loading Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Super Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Json Sets\n",
    "def load_checkpoint_1():\n",
    "    super_df = {}\n",
    "    for label in params['data_labels']:\n",
    "        for val, _ in enumerate(params[ label ]):\n",
    "            super_df[ label+str(val) ] = pd.read_json( params['output_pandas'] / (label+str(val) +'.json')  )\n",
    "            print(\"read:\",label+str(val))\n",
    "    return super_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read: test_raw0\n",
      "read: test_raw1\n"
     ]
    }
   ],
   "source": [
    "super_data = load_checkpoint_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Super Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_raw0</th>\n",
       "      <th>test_raw_bpe0</th>\n",
       "      <th>method_size0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DateUtils { public static Date yearStart() { f...</td>\n",
       "      <td>[Date, Ut, ils, Ġ{, Ġpublic, Ġstatic, ĠDate, Ġ...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           test_raw0  \\\n",
       "0  DateUtils { public static Date yearStart() { f...   \n",
       "\n",
       "                                       test_raw_bpe0  method_size0  \n",
       "0  [Date, Ut, ils, Ġ{, Ġpublic, Ġstatic, ĠDate, Ġ...           227  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_data['test_raw0'].head(1) #Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   78388.00\n",
       "mean      423.42\n",
       "std       653.26\n",
       "min         8.00\n",
       "25%       143.00\n",
       "50%       248.00\n",
       "75%       446.00\n",
       "max     31638.00\n",
       "Name: method_size0, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size Statistics of Source Set\n",
    "super_data['test_raw0'].method_size0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   9445.00\n",
       "mean      73.55\n",
       "std       18.59\n",
       "min        8.00\n",
       "25%       60.00\n",
       "50%       76.00\n",
       "75%       89.00\n",
       "max      100.00\n",
       "Name: method_size0, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SET_METHOD_SIZE = 100 #<---- HARDCODED\n",
    "super_data['test_raw0'][super_data['test_raw0'].method_size0 <= SET_METHOD_SIZE ].method_size0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_raw1</th>\n",
       "      <th>test_raw_bpe1</th>\n",
       "      <th>method_size1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Test public void yearStart() { Date date = Da...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġyear, Start, (), Ġ{...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           test_raw1  \\\n",
       "0  @Test public void yearStart() { Date date = Da...   \n",
       "\n",
       "                                       test_raw_bpe1  method_size1  \n",
       "0  [@, Test, Ġpublic, Ġvoid, Ġyear, Start, (), Ġ{...            61  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target Set\n",
    "super_data['test_raw1'].head(1) #Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a pretrain model\n",
    "model = TransformerModel.from_pretrained(\n",
    "  model_name_or_path = params['model_name_or_path'],\n",
    "  checkpoint_file = params['checkpoint_file'],\n",
    "  #data_name_or_path = params['data_preprocessed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): BARTModel(\n",
       "      (encoder): TransformerEncoderBase(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50348, 512, padding_idx=1)\n",
       "        (embed_positions): SinusoidalPositionalEmbedding()\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): TransformerDecoderBase(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50348, 512, padding_idx=1)\n",
       "        (embed_positions): SinusoidalPositionalEmbedding()\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (output_projection): Linear(in_features=512, out_features=50348, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Move model to GPU if available and trigger evaluation mode\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model = model.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joining_encode_tokens( arr_tokens, model ):\n",
    "    if len(arr_tokens) > SET_METHOD_SIZE:\n",
    "        arr_tokens = arr_tokens[0:SET_METHOD_SIZE]\n",
    "    focal_code = \" \".join(arr_tokens)\n",
    "    return model.encode( focal_code )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling without replacement\n",
    "#Testing size: 78388\n",
    "#Sampling size with 95% of confidence and 3% Error = 1053 ~ 1000\n",
    "def code_sampling(df_super_data ,  FLAG_SAMPLING = True, SIZE_SAMPLING = 1000, random_state = 3): #<---- HARDCODED\n",
    "    \n",
    "    df_sampled_code = df_super_data['test_raw0'][df_super_data['test_raw0'].method_size0 <= SET_METHOD_SIZE ].sample(\n",
    "            n = SIZE_SAMPLING,\n",
    "            replace = False,\n",
    "            random_state = random_state # For reproducibility\n",
    "    )\n",
    "\n",
    "    if FLAG_SAMPLING:\n",
    "        df_sampled_code['input_tokens'] = [ joining_encode_tokens(arr_sample, model=model) for arr_sample in df_sampled_code.test_raw_bpe0.values ]\n",
    "        #df_sampled_code['origin_pos'] = df_sampled_code.index\n",
    "    else:\n",
    "        df_sampled_code['input_tokens_pos'] = [ joining_encode_tokens(arr_sample, model=model) for arr_sample in df_super_data['test_raw0'].test_raw_bpe0.values]\n",
    "        #df_sampled_code['origin'] = df_sampled_code.index\n",
    "    return df_sampled_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled_code = code_sampling(\n",
    "    df_super_data = super_data,\n",
    "    SIZE_SAMPLING = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_raw0</th>\n",
       "      <th>test_raw_bpe0</th>\n",
       "      <th>method_size0</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>DropImpl extends BaseSqlPart implements Drop {...</td>\n",
       "      <td>[Drop, Impl, Ġextends, ĠBase, S, ql, Part, Ġim...</td>\n",
       "      <td>162</td>\n",
       "      <td>[tensor(43542), tensor(48455), tensor(14269), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71045</th>\n",
       "      <td>RuleDatabaseItemUpdateRunnable implements Runn...</td>\n",
       "      <td>[Rule, Database, Item, Update, Run, n, able, Ġ...</td>\n",
       "      <td>183</td>\n",
       "      <td>[tensor(47181), tensor(49187), tensor(47599), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30570</th>\n",
       "      <td>InChIToStructure { public IAtomContainer getAt...</td>\n",
       "      <td>[In, Ch, IT, o, St, ructure, Ġ{, Ġpublic, ĠI, ...</td>\n",
       "      <td>123</td>\n",
       "      <td>[tensor(1121), tensor(4771), tensor(2068), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28852</th>\n",
       "      <td>SgfParser { public List&lt;Short&gt; parseGameFromFi...</td>\n",
       "      <td>[S, g, f, Parser, Ġ{, Ġpublic, ĠList, &lt;, Short...</td>\n",
       "      <td>150</td>\n",
       "      <td>[tensor(104), tensor(571), tensor(506), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54142</th>\n",
       "      <td>PredictionContainerGenerator extends AbstractA...</td>\n",
       "      <td>[Pred, iction, Container, Gener, ator, Ġextend...</td>\n",
       "      <td>162</td>\n",
       "      <td>[tensor(45408), tensor(26579), tensor(48557), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               test_raw0  \\\n",
       "5394   DropImpl extends BaseSqlPart implements Drop {...   \n",
       "71045  RuleDatabaseItemUpdateRunnable implements Runn...   \n",
       "30570  InChIToStructure { public IAtomContainer getAt...   \n",
       "28852  SgfParser { public List<Short> parseGameFromFi...   \n",
       "54142  PredictionContainerGenerator extends AbstractA...   \n",
       "\n",
       "                                           test_raw_bpe0  method_size0  \\\n",
       "5394   [Drop, Impl, Ġextends, ĠBase, S, ql, Part, Ġim...           162   \n",
       "71045  [Rule, Database, Item, Update, Run, n, able, Ġ...           183   \n",
       "30570  [In, Ch, IT, o, St, ructure, Ġ{, Ġpublic, ĠI, ...           123   \n",
       "28852  [S, g, f, Parser, Ġ{, Ġpublic, ĠList, <, Short...           150   \n",
       "54142  [Pred, iction, Container, Gener, ator, Ġextend...           162   \n",
       "\n",
       "                                            input_tokens  \n",
       "5394   [tensor(43542), tensor(48455), tensor(14269), ...  \n",
       "71045  [tensor(47181), tensor(49187), tensor(47599), ...  \n",
       "30570  [tensor(1121), tensor(4771), tensor(2068), ten...  \n",
       "28852  [tensor(104), tensor(571), tensor(506), tensor...  \n",
       "54142  [tensor(45408), tensor(26579), tensor(48557), ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sampled_code.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#super_data['test_raw0'].filter( items = df_sampled_code.origin_pos.values, axis=0 ) #<-------- Retrieving original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sampled_code.input_tokens.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43542, 48455, 14269, 11056,   104, 44306,  4741, 36987, 21603, 25522,\n",
       "          787,  7199, 49302,   787, 49116,   285, 21603, 41836,  2103,  1640,\n",
       "         1039,  7199, 49302,   507, 26602,  2103, 31723,    43, 25522,   671,\n",
       "         2103,  1640, 15755,     6,  2103, 31723,  4397, 35524,   787,  7199,\n",
       "        49302,   787, 49116, 21603, 41836,  2103,  1640,  1039,  7199, 49302,\n",
       "          507, 26602,  2103, 31723,  4397,   787,  7199, 49302,   787, 49116,\n",
       "        21603, 41836,  2103,  1640,  1039, 49302,   868,   507, 26602,  8503,\n",
       "        31723,     6,   787,  7199, 49302,   507, 26602,  2103, 31723,  4397,\n",
       "          787,  7199, 49302,   787, 49116, 21603, 41836,  1106,  9089,  1952,\n",
       "         2103,  1106,  9089,  1952,  1640,  1039,  7199, 49302,   507, 26602,\n",
       "         2103, 31723,  4397,   787,  7199, 49302,   787, 49116, 21603, 41836,\n",
       "         1106,  9089,  1952,  2103,  1106,  9089,  1952,  1640,  1039, 49302,\n",
       "          868,   507, 26602,  8503, 31723,     6,   787,  7199, 49302,   507,\n",
       "        26602,  2103, 31723,  4397,   787, 49116, 13842, 12760,  1397,  3972,\n",
       "         1640,  1039,  7199, 49302,   507,  8214,   104, 44306, 45200, 20528,\n",
       "         4397,   787, 49302,   868,   787, 49116,   208, 44306,  4741,   986,\n",
       "        47006, 35524,     2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled_code.input_tokens.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 30 #<---- Hardocoded\n",
    "MAX_GEN_TOK = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sample_generation(\n",
    "    df_sampled_code, \n",
    "    model, \n",
    "    n=1, \n",
    "    max_gen_tok = 100\n",
    "    ):\n",
    "    generated_input = lambda input,model,n,max_gen_tok: model.generate( \n",
    "        input,\n",
    "        beam = n, \n",
    "        maxlen = max_gen_tok, ##WARNING, This parameter is not working\n",
    "        #max_length = n, \n",
    "        do_sample = False, \n",
    "        pad_token_id = 50256 ) ## HARDCODED\n",
    "    arr_generated_code = np.array([ generated_input(input, model=model, n=n, \n",
    "                                max_gen_tok=max_gen_tok ) for input in df_sampled_code.input_tokens.values ]).T\n",
    "    \n",
    "    #dict_generated_code = { i: [j['tokens'].cpu().data.numpy()[:max_gen_tok] for j in samples] for i,samples in enumerate(arr_generated_code) } #Max Token Generation\n",
    "    dict_generated_code = { i: [j['tokens'].cpu().data.numpy() for j in samples] for i,samples in enumerate(arr_generated_code) }\n",
    "    dict_generated_code['source_sampling'] = [ i.cpu().data.numpy() for i in df_sampled_code.input_tokens.values] \n",
    "    #return arr_generated_code\n",
    "    df_temp = pd.DataFrame().from_dict( data=dict_generated_code ) # DataFrame from Generation\n",
    "    df_temp = pd.concat([df_sampled_code.reset_index(), df_temp ], axis=1) #Index before concating\n",
    "    #return pd.DataFrame().from_dict( data=dict_generated_code )\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO limit the number of tokens generated\n",
    "#WARNING TIME CONSUMING\n",
    "df_generated_input = df_sample_generation( \n",
    "    df_sampled_code = df_sampled_code, \n",
    "    model = model, \n",
    "    n = SAMPLES, \n",
    "    max_gen_tok = MAX_GEN_TOK \n",
    ")\n",
    "# [ sample_generation(input, model=model) for input in input_tokens[:2] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_raw0</th>\n",
       "      <th>test_raw_bpe0</th>\n",
       "      <th>method_size0</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>source_sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5394</td>\n",
       "      <td>DropImpl extends BaseSqlPart implements Drop {...</td>\n",
       "      <td>[Drop, Impl, Ġextends, ĠBase, S, ql, Part, Ġim...</td>\n",
       "      <td>162</td>\n",
       "      <td>[tensor(43542), tensor(48455), tensor(14269), ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[43542, 48455, 14269, 11056, 104, 44306, 4741,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71045</td>\n",
       "      <td>RuleDatabaseItemUpdateRunnable implements Runn...</td>\n",
       "      <td>[Rule, Database, Item, Update, Run, n, able, Ġ...</td>\n",
       "      <td>183</td>\n",
       "      <td>[tensor(47181), tensor(49187), tensor(47599), ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[47181, 49187, 47599, 39962, 33177, 282, 868, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30570</td>\n",
       "      <td>InChIToStructure { public IAtomContainer getAt...</td>\n",
       "      <td>[In, Ch, IT, o, St, ructure, Ġ{, Ġpublic, ĠI, ...</td>\n",
       "      <td>123</td>\n",
       "      <td>[tensor(1121), tensor(4771), tensor(2068), ten...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1121, 4771, 2068, 139, 5320, 20636, 25522, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28852</td>\n",
       "      <td>SgfParser { public List&lt;Short&gt; parseGameFromFi...</td>\n",
       "      <td>[S, g, f, Parser, Ġ{, Ġpublic, ĠList, &lt;, Short...</td>\n",
       "      <td>150</td>\n",
       "      <td>[tensor(104), tensor(571), tensor(506), tensor...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 22011, 1090, 20...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 22011, 1090, 20...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[104, 571, 506, 49707, 25522, 285, 9527, 41552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54142</td>\n",
       "      <td>PredictionContainerGenerator extends AbstractA...</td>\n",
       "      <td>[Pred, iction, Container, Gener, ator, Ġextend...</td>\n",
       "      <td>162</td>\n",
       "      <td>[tensor(45408), tensor(26579), tensor(48557), ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[45408, 26579, 48557, 40025, 2630, 14269, 4364...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          test_raw0  \\\n",
       "0   5394  DropImpl extends BaseSqlPart implements Drop {...   \n",
       "1  71045  RuleDatabaseItemUpdateRunnable implements Runn...   \n",
       "2  30570  InChIToStructure { public IAtomContainer getAt...   \n",
       "3  28852  SgfParser { public List<Short> parseGameFromFi...   \n",
       "4  54142  PredictionContainerGenerator extends AbstractA...   \n",
       "\n",
       "                                       test_raw_bpe0  method_size0  \\\n",
       "0  [Drop, Impl, Ġextends, ĠBase, S, ql, Part, Ġim...           162   \n",
       "1  [Rule, Database, Item, Update, Run, n, able, Ġ...           183   \n",
       "2  [In, Ch, IT, o, St, ructure, Ġ{, Ġpublic, ĠI, ...           123   \n",
       "3  [S, g, f, Parser, Ġ{, Ġpublic, ĠList, <, Short...           150   \n",
       "4  [Pred, iction, Container, Gener, ator, Ġextend...           162   \n",
       "\n",
       "                                        input_tokens  \\\n",
       "0  [tensor(43542), tensor(48455), tensor(14269), ...   \n",
       "1  [tensor(47181), tensor(49187), tensor(47599), ...   \n",
       "2  [tensor(1121), tensor(4771), tensor(2068), ten...   \n",
       "3  [tensor(104), tensor(571), tensor(506), tensor...   \n",
       "4  [tensor(45408), tensor(26579), tensor(48557), ...   \n",
       "\n",
       "                                                   0  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 197, 22011, 1090, 20...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 44840, 26170,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   4  ...  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...  ...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...  ...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...  ...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...  ...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...  ...   \n",
       "\n",
       "                                                  21  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  22  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  23  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  24  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  25  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  26  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  27  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  28  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 197, 22011, 1090, 20...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  29  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                     source_sampling  \n",
       "0  [43542, 48455, 14269, 11056, 104, 44306, 4741,...  \n",
       "1  [47181, 49187, 47599, 39962, 33177, 282, 868, ...  \n",
       "2  [1121, 4771, 2068, 139, 5320, 20636, 25522, 28...  \n",
       "3  [104, 571, 506, 49707, 25522, 285, 9527, 41552...  \n",
       "4  [45408, 26579, 48557, 40025, 2630, 14269, 4364...  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics and Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_len_method = [ (np.array([ len(gen_method) for gen_method in df_generated_input[j] ]).mean(),\n",
    "                   np.array([ len(gen_method) for gen_method in df_generated_input[j] ]).std()  )\n",
    "                    for j in range(30) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(112.2, 62.92980216082043),\n",
       " (112.0, 62.504399845130905),\n",
       " (108.0, 61.13264267148934),\n",
       " (107.4, 59.87520354871455),\n",
       " (107.6, 60.45361858482915),\n",
       " (104.8, 59.96465625683182),\n",
       " (102.8, 58.714223149080325),\n",
       " (102.2, 58.87410296556543),\n",
       " (102.4, 58.72852799108794),\n",
       " (100.0, 58.32323722153975),\n",
       " (103.0, 60.02666074337302),\n",
       " (100.0, 58.22370651203855),\n",
       " (101.0, 59.32284551502903),\n",
       " (99.4, 58.67742325630872),\n",
       " (97.2, 58.34175177349408),\n",
       " (95.2, 57.241243871879654),\n",
       " (94.4, 58.3869848510779),\n",
       " (92.6, 58.711498022108074),\n",
       " (90.8, 58.89448191469214),\n",
       " (92.8, 57.80449809487147),\n",
       " (92.8, 57.880566686928695),\n",
       " (90.0, 59.03558249056242),\n",
       " (91.8, 58.47871407614912),\n",
       " (85.0, 61.59545437773797),\n",
       " (81.4, 60.88875101363141),\n",
       " (79.6, 62.31725282776833),\n",
       " (78.8, 62.268451080784075),\n",
       " (82.4, 60.65509047062744),\n",
       " (82.0, 61.01803012225157),\n",
       " (74.0, 65.78145635359557)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_len_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoint of Generation\n",
    "def checkpoint_generation( df , name = '1_generation_[max:100]_02.json' ):\n",
    "    df.drop('input_tokens', axis=1).to_json( params['output_results'] + name )\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_generation( df = df_generated_input )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generated_input = pd.read_json( params['output_results'] + '1_generation_[max:100]_02.json' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_raw0</th>\n",
       "      <th>test_raw_bpe0</th>\n",
       "      <th>method_size0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>source_sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5394</td>\n",
       "      <td>DropImpl extends BaseSqlPart implements Drop {...</td>\n",
       "      <td>[Drop, Impl, Ġextends, ĠBase, S, ql, Part, Ġim...</td>\n",
       "      <td>162</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[43542, 48455, 14269, 11056, 104, 44306, 4741,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71045</td>\n",
       "      <td>RuleDatabaseItemUpdateRunnable implements Runn...</td>\n",
       "      <td>[Rule, Database, Item, Update, Run, n, able, Ġ...</td>\n",
       "      <td>183</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 44514, 43048, 6...</td>\n",
       "      <td>[47181, 49187, 47599, 39962, 33177, 282, 868, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30570</td>\n",
       "      <td>InChIToStructure { public IAtomContainer getAt...</td>\n",
       "      <td>[In, Ch, IT, o, St, ructure, Ġ{, Ġpublic, ĠI, ...</td>\n",
       "      <td>123</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 3750, 1...</td>\n",
       "      <td>[1121, 4771, 2068, 139, 5320, 20636, 25522, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28852</td>\n",
       "      <td>SgfParser { public List&lt;Short&gt; parseGameFromFi...</td>\n",
       "      <td>[S, g, f, Parser, Ġ{, Ġpublic, ĠList, &lt;, Short...</td>\n",
       "      <td>150</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 22011, 1090, 20...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 197, 22011, 1090, 20...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 22011, 1090, 2...</td>\n",
       "      <td>[104, 571, 506, 49707, 25522, 285, 9527, 41552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54142</td>\n",
       "      <td>PredictionContainerGenerator extends AbstractA...</td>\n",
       "      <td>[Pred, iction, Container, Gener, ator, Ġextend...</td>\n",
       "      <td>162</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 21527, 45788, ...</td>\n",
       "      <td>[45408, 26579, 48557, 40025, 2630, 14269, 4364...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          test_raw0  \\\n",
       "0   5394  DropImpl extends BaseSqlPart implements Drop {...   \n",
       "1  71045  RuleDatabaseItemUpdateRunnable implements Runn...   \n",
       "2  30570  InChIToStructure { public IAtomContainer getAt...   \n",
       "3  28852  SgfParser { public List<Short> parseGameFromFi...   \n",
       "4  54142  PredictionContainerGenerator extends AbstractA...   \n",
       "\n",
       "                                       test_raw_bpe0  method_size0  \\\n",
       "0  [Drop, Impl, Ġextends, ĠBase, S, ql, Part, Ġim...           162   \n",
       "1  [Rule, Database, Item, Update, Run, n, able, Ġ...           183   \n",
       "2  [In, Ch, IT, o, St, ructure, Ġ{, Ġpublic, ĠI, ...           123   \n",
       "3  [S, g, f, Parser, Ġ{, Ġpublic, ĠList, <, Short...           150   \n",
       "4  [Pred, iction, Container, Gener, ator, Ġextend...           162   \n",
       "\n",
       "                                                   0  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 197, 22011, 1090, 20...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 44840, 26170,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                   5  ...  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 44840, 26170,...  ...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...  ...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...  ...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...  ...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...  ...   \n",
       "\n",
       "                                                  21  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  22  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  23  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  24  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  25  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  26  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  27  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  28  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 197, 22011, 1090, 20...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                                  29  \\\n",
       "0  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "1  [1039, 34603, 285, 13842, 197, 44514, 43048, 6...   \n",
       "2  [1039, 34603, 285, 13842, 1296, 14181, 3750, 1...   \n",
       "3  [1039, 34603, 285, 13842, 1296, 22011, 1090, 2...   \n",
       "4  [1039, 34603, 285, 13842, 1296, 21527, 45788, ...   \n",
       "\n",
       "                                     source_sampling  \n",
       "0  [43542, 48455, 14269, 11056, 104, 44306, 4741,...  \n",
       "1  [47181, 49187, 47599, 39962, 33177, 282, 868, ...  \n",
       "2  [1121, 4771, 2068, 139, 5320, 20636, 25522, 28...  \n",
       "3  [104, 571, 506, 49707, 25522, 285, 9527, 41552...  \n",
       "4  [45408, 26579, 48557, 40025, 2630, 14269, 4364...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ Test ( expected Ġ= ĠIllegal Arg ument Exception . class ) Ġpublic Ġvoid Ġtest Drop Table Null Table () Ġ{ Ġdrop . table ( null ); Ġ}'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tst decoding\n",
    "decoded = model.decode(df_generated_input['1'][0])\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Test(expected = IllegalArgumentException.class) public void testDropTableNullTable() {\\n     drop.table(null);\\n }\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettify_java( lazy_decode( decoded ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2262140/3033498944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## MEMORy DEALLOCATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "## MEMORy DEALLOCATION\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27c2fcb21fdb148cd37ecbed2ef65b6b1f3a0948b222c0bcf7dcf1d6a4c7a458"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('shapley-01': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
