{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rationalization @ Global Granularity\n",
    "> GPT-2 based global rationalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-07-13 20:49:06.515351: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 20:49:06.720195: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import importlib\n",
    "from matplotlib import colors\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/workspaces/code-rationales/sequential-rationales/huggingface')\n",
    "from rationalization import rationalize_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    return {\n",
    "        'model_name' : '/workspaces/code-rationales/data/codeparrot-small/checkpoints/checkpoint-29000', \n",
    "        'cache_dir': '/workspaces/code-rationales/datax/df_cache_dir',\n",
    "        #'dataset' : 'code_completion_random_cut_5k_30_512_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_random_cut_3.8k_30_150_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_signature_3.8k_30_150_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_5k_30_150_tokens',\n",
    "        'dataset' : 'code_completion_docstring_signature_5k_30_512_tokens',\n",
    "        'sampling_results': '/workspaces/code-rationales/data/sampling/gpt',\n",
    "        'rational_results': '/workspaces/code-rationales/data/rationales/gpt',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            param_default()['model_name'],\n",
    "            cache_dir=param_default()['cache_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(32768, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(param_default()['model_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Code Generation\n",
    "df_generated_input = pd.read_csv( param_default()['sampling_results'] + '/' + param_default()['dataset'] +'.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
       "       '25', '26', '27', '28', '29'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input.columns[5:] #Tensor Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>size</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Generate Pyhton code that Tests checkboxes but...</td>\n",
       "      <td>Tests checkboxes but also acts a regression te...</td>\n",
       "      <td>50</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Generate Pyhton code that \\n        Factory me...</td>\n",
       "      <td>\\n        Factory method to produce an instanc...</td>\n",
       "      <td>45</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Generate Pyhton code that True if this Entry h...</td>\n",
       "      <td>True if this Entry has references from any App...</td>\n",
       "      <td>52</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Generate Pyhton code that Set packet parent.\\n...</td>\n",
       "      <td>Set packet parent.\\n        When packet is an ...</td>\n",
       "      <td>52</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Generate Pyhton code that Remove packet parent...</td>\n",
       "      <td>Remove packet parent.\\n        When packet is ...</td>\n",
       "      <td>52</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             prompt  \\\n",
       "0      0  Generate Pyhton code that Tests checkboxes but...   \n",
       "1      1  Generate Pyhton code that \\n        Factory me...   \n",
       "2      2  Generate Pyhton code that True if this Entry h...   \n",
       "3      3  Generate Pyhton code that Set packet parent.\\n...   \n",
       "4      4  Generate Pyhton code that Remove packet parent...   \n",
       "\n",
       "                                        ground_truth  size  \\\n",
       "0  Tests checkboxes but also acts a regression te...    50   \n",
       "1  \\n        Factory method to produce an instanc...    45   \n",
       "2  True if this Entry has references from any App...    52   \n",
       "3  Set packet parent.\\n        When packet is an ...    52   \n",
       "4  Remove packet parent.\\n        When packet is ...    52   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   0  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   4  ...  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...  ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...  ...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...  ...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...  ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...  ...   \n",
       "\n",
       "                                                  20  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  21  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  22  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  23  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  24  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  25  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  26  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  27  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  28  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  29  \n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...  \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...  \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...  \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...  \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 35)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generate Pyhton code that \\n        Factory method to produce an instance of this class using the default kube config location\\n         and signature is def from_environment(cls):\\n            with open(os.environ[\\'WORKER_CRAMDOOT\\'], \\'r\\') as f:\\n                f.read() \\n    from_configuration = Factory({\\n        \\n       \\'version\\': u\\'\\'\\n        })\\n    from_config.from_config_path()\\n\\n    from_context_manager = Factory(dict(\\n        uuid\\n        u\\'username\\': u\\'berry\\',\\n        u\\'password\\': u\\'password\\'\\n    ),\\n        dict(username = u\\'berry\\', password = u\\'pass\\'\\n    ),\\n        u\\'BOOKE_API_KEY\\': oxo_site_config[\"BOOKE_API_KEY\"]\\n    )\\n\\n    return HttpContext(options_dict(\\n        filtered_services=[\"requests\", \\n                             config_manager, \\n                             config_loader,\\n                             config_finders,\\n                             config_finds_dir,\\n                            config_manager_is_imported,\\n                            config_manager_args,\\n                            config_loader_log\"]),\\n        run_args={\"requests\": advanced_group, \"search\": advanced_search, \"search_pages\": advanced_search_pages, \"streaming\": advanced_streaming, \"client\": custom_client}\\n    ))\\n                      \\n           \\n        # kwarg to the class\\n        setup=from_configuration[\"setup\"],\\n        tool=blueprint_tools.toolhOLDER_COMMAND_SERVER_ARG,\\n        config_manager=from_configuration[\"config_manager\"],\\n        server=config_manager.get(\\'server\\', \\'127.0.0.1\\'),\\n        config_loader=from_configuration[\"client\"],\\n        context=from_context_manager,\\n        config_finders=config_finders,\\n        env=vmdk_session.get_nt_context()\\n    ))\\nclass Artifact(with_cached_http=True,\\n           controller=artifact_manager.ArtifactManagerController):\\n    \"\"\"\\n    A generator around a python script inside the Bokeh server.\\n    \\n    Use this class to make an zeros spark web client mounted in the session and attach a python script\\n     to it as a decorator. This decorator will attach an object to a'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tst decoding\n",
    "decoded = tokenizer.decode(eval(df_generated_input['0'][1]))\n",
    "decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Statistics\n",
    "np.mean( [len(eval(i)) for i in df_generated_input['0'].values] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Run the distribution of each experiment. The mean value of tokens or size for each experiment. \n",
    "np.mean( [len(eval(i)) for i in df_generated_input['input_ids'].values] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2392"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_generated_input['0'].values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_SIZE = df_generated_input['size'].max() #Hardocoded!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the model is not fine-tuned or compatible, it will rise an error\n",
    "#This function works for one tensor of source token and one tensor of target tokens\n",
    "def rationalize_model(model, tokenizer, input_ids, verbose=True):\n",
    "    all_rationales, log = rationalize_lm(\n",
    "        model = model,\n",
    "        input_ids = input_ids[:MAX_TOKEN_SIZE],\n",
    "        tokenizer = tokenizer,\n",
    "        verbose = verbose,\n",
    "        max_steps=1024 #Max number of steps for greedy rationalization\n",
    "    )\n",
    "    return all_rationales, log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst <------- Test Case 2\n",
    "def tst_rationalize_model():\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    #WARNING TIME CONSUMING\n",
    "    all_rationales, log = rationalize_model(\n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        input_ids=torch.tensor(eval(df_generated_input['0'][0])).to(model.device),\n",
    "        verbose=False\n",
    "    )\n",
    "    pass\n",
    "tst_rationalize_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_rational(\n",
    "    model,\n",
    "    tokenizer, \n",
    "    arr_target_tokens, \n",
    "    seq_id, #mapping sequence id\n",
    "    verbose=True\n",
    "):\n",
    "    arr_log = []\n",
    "    for index, val in enumerate(arr_target_tokens):\n",
    "        all_rationales, log = rationalize_model(\n",
    "            model=model, \n",
    "            tokenizer=tokenizer, \n",
    "            input_ids=val,\n",
    "            verbose=False\n",
    "        )\n",
    "        arr_log.append(log)\n",
    "    arr_code_rationales = [ log['rationalization'] for log in arr_log ] #extracting just rationalizations\n",
    "    arr_from_sentence = [ list(np.full( len(val), seq_id[arr_i] )) #arr_i maps to the real sequence id\n",
    "                            for arr_i, val in enumerate(arr_code_rationales)]\n",
    "    arr_code_rationales = sum( arr_code_rationales, [] ) #flatting\n",
    "    arr_from_sentence = sum( arr_from_sentence, [] ) #flatting\n",
    "    return arr_code_rationales, arr_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst <------- Test Case 2\n",
    "def tst_run_multiple_rationa():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    t_dict_generated_input = { exp : [ torch.tensor(eval(s)).to(model.device) for \n",
    "                s in df_generated_input[exp].values ] for exp in df_generated_input.columns[5:]  }\n",
    "    \n",
    "    arr_rations, seq_id = run_multiple_rational(\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        arr_target_tokens =  t_dict_generated_input['0'][:2], \n",
    "        seq_id = list( range(2,4) ),\n",
    "        verbose = False\n",
    "        )\n",
    "    return arr_rations, seq_id\n",
    "tst_arr_rations, seq_id = tst_run_multiple_rationa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_rationales( arr_code_rationales, arr_from_sentence ):\n",
    "    #Creating pandas_1 {p_rationale}\n",
    "    rational = lambda list_log,typeset: [ (dict_tok['added_token_text'],round(dict_tok['true_token_prob'],6)) for dict_tok in list_log if dict_tok['from']==typeset]\n",
    "    log = lambda log_row: [(log_dict['added_token_text'],log_dict['true_token_prob']) for log_dict in log_row] #Typeset\n",
    "\n",
    "    log_position = lambda log_row: [log_dict['added_token_position'] for log_dict in log_row] #Position of the Rationale\n",
    "    log_prediction = lambda log_row: [log_dict['true_token_prob'] for log_dict in log_row] #Rationale Prob\n",
    "\n",
    "    p_rationale = pd.DataFrame()\n",
    "\n",
    "    p_rationale['goal_token'] = [dict_token['goal_word'] for dict_token in arr_code_rationales]\n",
    "    p_rationale['from_seq_id'] = arr_from_sentence\n",
    "\n",
    "    p_rationale['typesets_tgt'] = [ log(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    \n",
    "    p_rationale['rationale_pos_tgt'] = [ log_position(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    p_rationale['rationale_prob_tgt'] = [ log_prediction(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "\n",
    "\n",
    "    return p_rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Rationalization\n",
    "def run_code_rational( \n",
    "        df_generated_input,\n",
    "        tensor_size, #Control the size of the experiment\n",
    "        experiment = '5',\n",
    "        batch_size = 100, \n",
    "        model = model, \n",
    "        verbose = True \n",
    "    ):\n",
    "\n",
    "    arr_rationals = []\n",
    "    arr_from_seq = []\n",
    "\n",
    "    for i in range( 0 , tensor_size , batch_size ):\n",
    "        print('************************' + str(i) + '************************')\n",
    "        t_generated_input = df_generated_input[experiment].values[i:i+batch_size]\n",
    "        t_generated_input = [ torch.tensor(eval(s)).to(model.device) for s in t_generated_input]\n",
    "\n",
    "        t_arr_rationals,t_arr_from_seq = run_multiple_rational(\n",
    "            model = model,\n",
    "            tokenizer = tokenizer,\n",
    "            arr_target_tokens =  t_generated_input, \n",
    "            seq_id = list(range(i,i+batch_size)),\n",
    "            verbose = verbose\n",
    "        )\n",
    "\n",
    "        arr_rationals = arr_rationals + t_arr_rationals\n",
    "        arr_from_seq = arr_from_seq + t_arr_from_seq\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() #Cleaning Cache\n",
    "\n",
    "    #keys_tensor = list( dict_generated_input.keys() )\n",
    "    #keys_tensor = keys_tensor[:1] #HardCoded Ratios\n",
    "    #dict_arr_rations = { key : for key in keys_tensor}\n",
    "    #torch.cuda.empty_cache() #Cleaning Cache\n",
    "    print(\"Experiment Finished: \" + experiment)\n",
    "    return pandas_rationales( arr_rationals, arr_from_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************0************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************1************************\n",
      "************************2************************\n",
      "Experiment Finished: 0\n"
     ]
    }
   ],
   "source": [
    "#tst\n",
    "def tst_run_code_rational_sampling_set(exp='0'):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    tensor_n = 3 #df_generated_input.shape[0]\n",
    "    EXP = exp\n",
    "    BATCH = 1\n",
    "    test_arr_rationals = run_code_rational( \n",
    "            df_generated_input = df_generated_input.sample( n = tensor_n, replace = False, random_state=2),\n",
    "            tensor_size = tensor_n,\n",
    "            experiment = EXP,\n",
    "            batch_size = BATCH, \n",
    "            model = model, \n",
    "            verbose = False \n",
    "        )\n",
    "    return test_arr_rationals\n",
    "df_test_run = tst_run_code_rational_sampling_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Py</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Generate, 7.423743954859674e-05)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[7.423743954859674e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>ht</td>\n",
       "      <td>1</td>\n",
       "      <td>[( Py, 0.00010367632057750598), (Generate, 2.5...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.00010367632057750598, 2.5881863621179946e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>[(ht, 0.003939895424991846), (Generate, 0.0129...</td>\n",
       "      <td>[2, 0, 1]</td>\n",
       "      <td>[0.003939895424991846, 0.012913737446069717, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>code</td>\n",
       "      <td>1</td>\n",
       "      <td>[(on, 8.253633131971583e-05), ( Py, 0.00018459...</td>\n",
       "      <td>[3, 1, 0, 2]</td>\n",
       "      <td>[8.253633131971583e-05, 0.00018459450802765787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>that</td>\n",
       "      <td>1</td>\n",
       "      <td>[( code, 0.0016732582589611411), (Generate, 0....</td>\n",
       "      <td>[4, 0, 1, 3, 2]</td>\n",
       "      <td>[0.0016732582589611411, 0.018313312903046608, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>[(lower, 0.015630951151251793), (METRICS, 0.31...</td>\n",
       "      <td>[458, 443]</td>\n",
       "      <td>[0.015630951151251793, 0.31624388694763184]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>promote</td>\n",
       "      <td>1</td>\n",
       "      <td>[(_, 1.509848516434431e-06), (promote, 0.00830...</td>\n",
       "      <td>[459, 122, 451]</td>\n",
       "      <td>[1.509848516434431e-06, 0.008305856958031654, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>()</td>\n",
       "      <td>1</td>\n",
       "      <td>[(promote, 0.04420287907123566), ((), 0.108644...</td>\n",
       "      <td>[460, 346, 272, 74]</td>\n",
       "      <td>[0.04420287907123566, 0.10864423960447311, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>[((), 0.3412705957889557)]</td>\n",
       "      <td>[461]</td>\n",
       "      <td>[0.3412705957889557]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>properties</td>\n",
       "      <td>1</td>\n",
       "      <td>[(\\n       , 0.00015490688383579254), ( proper...</td>\n",
       "      <td>[462, 446, 445]</td>\n",
       "      <td>[0.00015490688383579254, 0.016215959563851357,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      goal_token  from_seq_id  \\\n",
       "463           Py            1   \n",
       "464           ht            1   \n",
       "465           on            1   \n",
       "466         code            1   \n",
       "467         that            1   \n",
       "..           ...          ...   \n",
       "921            _            1   \n",
       "922      promote            1   \n",
       "923           ()            1   \n",
       "924    \\n                   1   \n",
       "925   properties            1   \n",
       "\n",
       "                                          typesets_tgt    rationale_pos_tgt  \\\n",
       "463                [(Generate, 7.423743954859674e-05)]                  [0]   \n",
       "464  [( Py, 0.00010367632057750598), (Generate, 2.5...               [1, 0]   \n",
       "465  [(ht, 0.003939895424991846), (Generate, 0.0129...            [2, 0, 1]   \n",
       "466  [(on, 8.253633131971583e-05), ( Py, 0.00018459...         [3, 1, 0, 2]   \n",
       "467  [( code, 0.0016732582589611411), (Generate, 0....      [4, 0, 1, 3, 2]   \n",
       "..                                                 ...                  ...   \n",
       "921  [(lower, 0.015630951151251793), (METRICS, 0.31...           [458, 443]   \n",
       "922  [(_, 1.509848516434431e-06), (promote, 0.00830...      [459, 122, 451]   \n",
       "923  [(promote, 0.04420287907123566), ((), 0.108644...  [460, 346, 272, 74]   \n",
       "924                         [((), 0.3412705957889557)]                [461]   \n",
       "925  [(\\n       , 0.00015490688383579254), ( proper...      [462, 446, 445]   \n",
       "\n",
       "                                    rationale_prob_tgt  \n",
       "463                            [7.423743954859674e-05]  \n",
       "464   [0.00010367632057750598, 2.5881863621179946e-05]  \n",
       "465  [0.003939895424991846, 0.012913737446069717, 0...  \n",
       "466  [8.253633131971583e-05, 0.00018459450802765787...  \n",
       "467  [0.0016732582589611411, 0.018313312903046608, ...  \n",
       "..                                                 ...  \n",
       "921        [0.015630951151251793, 0.31624388694763184]  \n",
       "922  [1.509848516434431e-06, 0.008305856958031654, ...  \n",
       "923  [0.04420287907123566, 0.10864423960447311, 0.1...  \n",
       "924                               [0.3412705957889557]  \n",
       "925  [0.00015490688383579254, 0.016215959563851357,...  \n",
       "\n",
       "[463 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tst\n",
    "df_test_run[ df_test_run['from_seq_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_rational_all_set(exp, tensor_n = 100, BATCH = 10): #When Tensor_n and batch differs then 'from_seq_id' is lost\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    EXP = exp\n",
    "    test_arr_rationals = run_code_rational( \n",
    "            df_generated_input = df_generated_input,\n",
    "            tensor_size = tensor_n,\n",
    "            experiment = EXP,\n",
    "            batch_size = BATCH, \n",
    "            model = model, \n",
    "            verbose = False \n",
    "        )\n",
    "    #Saving process\n",
    "    print('Saving process')\n",
    "    test_arr_rationals.to_csv(param_default()['rational_results'] + '/' + param_default()['dataset'] + '/' + '[t_'+str(tensor_n)+']_[max_tgt_'+str(MAX_TOKEN_SIZE)+']_[exp:' + str(EXP) +'].csv')\n",
    "    return test_arr_rationals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst\n",
    "#df_test_run = run_code_rational_all_set(exp='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************0************************\n",
      "************************10************************\n"
     ]
    }
   ],
   "source": [
    "for i in df_generated_input.columns[5:]: #Only Generated Sequences \n",
    "    df_test_run = run_code_rational_all_set(exp=i, tensor_n=df_generated_input.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>skip</td>\n",
       "      <td>0</td>\n",
       "      <td>[(def, 0.00029721998726017773)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.00029721998726017773]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  goal_token  from_seq_id                     typesets_tgt rationale_pos_tgt  \\\n",
       "0       skip            0  [(def, 0.00029721998726017773)]               [0]   \n",
       "\n",
       "         rationale_prob_tgt  \n",
       "0  [0.00029721998726017773]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_run.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running all Experiments\n",
    "def exp_run_all_rationales():\n",
    "    dict_arr_rations = { key : run_code_rational(\n",
    "        df_generated_input = df_generated_input,\n",
    "        experiment = key,\n",
    "        batch_size = 10, \n",
    "        model = model, \n",
    "        verbose = False \n",
    "    ) for key in df_generated_input.columns[5:] }\n",
    "    return dict_arr_rations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_df_rationale = [pandas_rationales(dict_arr_rations[key]) for key in dict_arr_rations.keys()]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27c2fcb21fdb148cd37ecbed2ef65b6b1f3a0948b222c0bcf7dcf1d6a4c7a458"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('shapley-01': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
